{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoREAL API Testing Suite\n",
    "\n",
    "This notebook provides comprehensive testing for all GoREAL API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# API Configuration\n",
    "API_BASE_URL = \"http://api:5000\"  # Docker service name\n",
    "# For local testing, use: API_BASE_URL = \"http://localhost:5000\"\n",
    "\n",
    "# Test data\n",
    "TEST_PLAYER_ID = \"TEST123\"\n",
    "TEST_PLAYER_NAME = \"Test_Player\"\n",
    "TEST_CHALLENGE_ID = \"C01\"\n",
    "\n",
    "print(f\"Testing API at: {API_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_health_check():\n",
    "    \"\"\"Test the health check endpoint\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/health\", timeout=10)\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n",
    "        return response.status_code == 200\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"=== HEALTH CHECK TEST ===\")\n",
    "health_ok = test_health_check()\n",
    "print(f\"Health Check Passed: {health_ok}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Challenge Logging Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_log_challenge(player_id, player_name, challenge_id):\n",
    "    \"\"\"Test the log challenge endpoint\"\"\"\n",
    "    payload = {\n",
    "        \"playerId\": player_id,\n",
    "        \"playerName\": player_name,\n",
    "        \"challengeId\": challenge_id\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{API_BASE_URL}/log_challenge\",\n",
    "            json=payload,\n",
    "            headers={'Content-Type': 'application/json'},\n",
    "            timeout=10\n",
    "        )\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n",
    "        return response.status_code == 200\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"=== LOG CHALLENGE TESTS ===\")\n",
    "\n",
    "# Test valid challenge logging\n",
    "print(\"\\n--- Test 1: Valid Challenge Log ---\")\n",
    "test1_passed = test_log_challenge(TEST_PLAYER_ID, TEST_PLAYER_NAME, TEST_CHALLENGE_ID)\n",
    "\n",
    "# Test with missing fields\n",
    "print(\"\\n--- Test 2: Missing Player Name ---\")\n",
    "invalid_payload = {\"playerId\": TEST_PLAYER_ID, \"challengeId\": TEST_CHALLENGE_ID}\n",
    "response = requests.post(f\"{API_BASE_URL}/log_challenge\", json=invalid_payload, timeout=10)\n",
    "print(f\"Status Code: {response.status_code} (Expected: 400)\")\n",
    "test2_passed = response.status_code == 400\n",
    "\n",
    "print(f\"\\nChallenge Logging Tests Passed: {test1_passed and test2_passed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Challenge Submission Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_submit_challenge(player_id, challenge_id, submission_text):\n",
    "    \"\"\"Test the submit challenge endpoint\"\"\"\n",
    "    payload = {\n",
    "        \"playerId\": player_id,\n",
    "        \"challengeId\": challenge_id,\n",
    "        \"submissionText\": submission_text\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{API_BASE_URL}/submit_challenge\",\n",
    "            json=payload,\n",
    "            headers={'Content-Type': 'application/json'},\n",
    "            timeout=10\n",
    "        )\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n",
    "        return response.status_code in [200, 404]  # 404 is valid if no prior log exists\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"=== SUBMIT CHALLENGE TESTS ===\")\n",
    "\n",
    "# Wait a moment to ensure the previous log challenge is processed\n",
    "time.sleep(2)\n",
    "\n",
    "# Test valid submission\n",
    "print(\"\\n--- Test 1: Valid Submission ---\")\n",
    "submission_text = \"I successfully completed the challenge! My room is now perfectly clean and organized.\"\n",
    "test1_passed = test_submit_challenge(TEST_PLAYER_ID, TEST_CHALLENGE_ID, submission_text)\n",
    "\n",
    "# Test submission without prior challenge log\n",
    "print(\"\\n--- Test 2: Submission Without Prior Log ---\")\n",
    "test2_passed = test_submit_challenge(\"NONEXISTENT123\", \"C99\", \"This should fail\")\n",
    "\n",
    "print(f\"\\nChallenge Submission Tests Passed: {test1_passed and test2_passed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Status Query Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_status(player_id, challenge_id):\n",
    "    \"\"\"Test the get status endpoint\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{API_BASE_URL}/get_status\",\n",
    "            params={'playerId': player_id, 'challengeId': challenge_id},\n",
    "            timeout=10\n",
    "        )\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n",
    "        return response.status_code in [200, 404]\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"=== STATUS QUERY TESTS ===\")\n",
    "\n",
    "# Test status query for existing challenge\n",
    "print(\"\\n--- Test 1: Query Existing Challenge Status ---\")\n",
    "test1_passed = test_get_status(TEST_PLAYER_ID, TEST_CHALLENGE_ID)\n",
    "\n",
    "# Test status query for non-existent challenge\n",
    "print(\"\\n--- Test 2: Query Non-existent Challenge ---\")\n",
    "test2_passed = test_get_status(\"FAKE123\", \"C999\")\n",
    "\n",
    "# Test with missing parameters\n",
    "print(\"\\n--- Test 3: Missing Parameters ---\")\n",
    "response = requests.get(f\"{API_BASE_URL}/get_status\", params={'playerId': TEST_PLAYER_ID}, timeout=10)\n",
    "print(f\"Status Code: {response.status_code} (Expected: 400)\")\n",
    "test3_passed = response.status_code == 400\n",
    "\n",
    "print(f\"\\nStatus Query Tests Passed: {test1_passed and test2_passed and test3_passed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Challenge List Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_challenges():\n",
    "    \"\"\"Test the get challenges endpoint\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/get_challenges\", timeout=10)\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        data = response.json()\n",
    "        print(f\"Number of challenges: {len(data.get('challenges', []))}\")\n",
    "        print(f\"Sample response: {json.dumps(data, indent=2)[:500]}...\")\n",
    "        return response.status_code == 200\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"=== GET CHALLENGES TEST ===\")\n",
    "challenges_test_passed = test_get_challenges()\n",
    "print(f\"\\nGet Challenges Test Passed: {challenges_test_passed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_api(num_requests=10):\n",
    "    \"\"\"Perform basic load testing on the API\"\"\"\n",
    "    print(f\"Starting load test with {num_requests} requests...\")\n",
    "    \n",
    "    success_count = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for i in range(num_requests):\n",
    "        player_id = f\"LOAD_TEST_{i}\"\n",
    "        player_name = f\"LoadTest_Player_{i}\"\n",
    "        challenge_id = f\"C0{(i % 5) + 1}\"  # Rotate through C01-C05\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        payload = {\n",
    "            \"playerId\": player_id,\n",
    "            \"playerName\": player_name,\n",
    "            \"challengeId\": challenge_id\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                f\"{API_BASE_URL}/log_challenge\",\n",
    "                json=payload,\n",
    "                headers={'Content-Type': 'application/json'},\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            request_time = end_time - start_time\n",
    "            total_time += request_time\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                success_count += 1\n",
    "            \n",
    "            print(f\"Request {i+1}: {response.status_code} ({request_time:.3f}s)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Request {i+1}: Error - {e}\")\n",
    "    \n",
    "    avg_time = total_time / num_requests\n",
    "    success_rate = (success_count / num_requests) * 100\n",
    "    \n",
    "    print(f\"\\n=== LOAD TEST RESULTS ===\")\n",
    "    print(f\"Total Requests: {num_requests}\")\n",
    "    print(f\"Successful Requests: {success_count}\")\n",
    "    print(f\"Success Rate: {success_rate:.1f}%\")\n",
    "    print(f\"Average Response Time: {avg_time:.3f}s\")\n",
    "    print(f\"Total Time: {total_time:.3f}s\")\n",
    "\n",
    "# Run load test\n",
    "load_test_api(5)  # Start with 5 requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test results summary\n",
    "test_results = {\n",
    "    'Test Category': [\n",
    "        'Health Check',\n",
    "        'Challenge Logging',\n",
    "        'Challenge Submission', \n",
    "        'Status Query',\n",
    "        'Challenge List',\n",
    "        'Load Testing'\n",
    "    ],\n",
    "    'Status': [\n",
    "        '✅ Passed' if health_ok else '❌ Failed',\n",
    "        '✅ Passed' if test1_passed and test2_passed else '❌ Failed',\n",
    "        '✅ Passed' if test1_passed and test2_passed else '❌ Failed',\n",
    "        '✅ Passed' if test1_passed and test2_passed and test3_passed else '❌ Failed',\n",
    "        '✅ Passed' if challenges_test_passed else '❌ Failed',\n",
    "        '✅ Completed' # Load test always completes, success depends on results\n",
    "    ],\n",
    "    'Description': [\n",
    "        'API health and endpoint availability',\n",
    "        'Challenge logging with validation',\n",
    "        'Proof submission functionality',\n",
    "        'Status query with error handling',\n",
    "        'Challenge list retrieval',\n",
    "        'Basic performance under load'\n",
    "    ]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(test_results)\n",
    "print(\"\\n=== GOREAL API TEST RESULTS SUMMARY ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Overall test status\n",
    "passed_tests = results_df['Status'].str.contains('Passed').sum()\n",
    "total_tests = len(results_df) - 1  # Exclude load test from pass/fail count\n",
    "print(f\"\\n📊 Overall Test Results: {passed_tests}/{total_tests} tests passed\")\n",
    "\n",
    "if passed_tests == total_tests:\n",
    "    print(\"🎉 All API tests passed! The API is functioning correctly.\")\n",
    "else:\n",
    "    print(\"⚠️  Some tests failed. Please review the API implementation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}