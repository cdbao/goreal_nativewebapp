name: Automated CI/CD Debugging and Fix

on:
  # Primary trigger: Automatic start when CI/CD workflows fail
  workflow_run:
    workflows: ["CI/CD Pipeline", "Deploy to Firebase"]
    types:
      - completed
    branches: [main]
  
  # Secondary triggers: Manual and scheduled
  workflow_dispatch:
    inputs:
      workflow_run_id:
        description: 'Specific workflow run ID to debug (optional)'
        required: false
        type: string
      force_analysis:
        description: 'Force analysis even if no recent failures'
        required: false
        type: boolean
        default: false
  schedule:
    # Backup check every 2 hours during business hours (UTC)  
    - cron: '0 */2 8-18 * * 1-5'

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'

jobs:
  # Step 1: Detect and Analyze Failures
  detect-failures:
    name: Detect CI/CD Failures
    runs-on: ubuntu-latest
    # Only run if: workflow failed, manual trigger, or scheduled
    if: >
      github.event.workflow_run.conclusion == 'failure' || 
      github.event_name == 'workflow_dispatch' || 
      github.event_name == 'schedule'
    
    outputs:
      has_failures: ${{ steps.detection.outputs.has_failures }}
      analysis_file: ${{ steps.detection.outputs.analysis_file }}
      triggered_by_failure: ${{ steps.detection.outputs.triggered_by_failure }}
      
    steps:
    - name: Wait for workflow logs to be available
      if: github.event.workflow_run.conclusion == 'failure'
      run: |
        echo "â±ï¸ Waiting 45 seconds for logs to be fully available..."
        echo "Failed workflow: ${{ github.event.workflow_run.name }}"
        echo "Run ID: ${{ github.event.workflow_run.id }}"
        echo "SHA: ${{ github.event.workflow_run.head_sha }}"
        sleep 45
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        
    - name: Install debugging system dependencies
      run: |
        cd .github/debugging-system
        npm init -y
        npm install @octokit/rest
        
    - name: Run failure detection and log analysis
      id: detection
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        GITHUB_REPOSITORY_OWNER: ${{ github.repository_owner }}
        GITHUB_REPOSITORY_NAME: ${{ github.event.repository.name }}
        WORKFLOW_RUN_ID: ${{ github.event.workflow_run.id }}
      run: |
        cd .github/debugging-system
        
        echo "ğŸ” Starting automated failure detection..."
        
        # Set triggered by failure flag
        if [ "${{ github.event.workflow_run.conclusion }}" == "failure" ]; then
          echo "triggered_by_failure=true" >> $GITHUB_OUTPUT
          echo "ğŸš¨ Triggered by workflow failure: ${{ github.event.workflow_run.name }}"
          echo "ğŸ“‹ Failed Run ID: ${{ github.event.workflow_run.id }}"
          
          # Use specific workflow run ID if available
          if [ -n "$WORKFLOW_RUN_ID" ]; then
            node log-retriever.js ci.yml "$WORKFLOW_RUN_ID"
          else
            node log-retriever.js ci.yml
          fi
        else
          echo "triggered_by_failure=false" >> $GITHUB_OUTPUT
          echo "ğŸ“… Triggered by: ${{ github.event_name }}"
          # Run standard analysis for scheduled/manual triggers
          node log-retriever.js ci.yml
        fi
        
        if [ -f "latest-failure-analysis.json" ]; then
          echo "has_failures=true" >> $GITHUB_OUTPUT
          echo "analysis_file=latest-failure-analysis.json" >> $GITHUB_OUTPUT
          echo "âœ… Failures detected and analyzed"
          
          # Display summary
          echo "ğŸ“Š Failure Summary:"
          node -e "
            const fs = require('fs');
            const data = JSON.parse(fs.readFileSync('latest-failure-analysis.json', 'utf8'));
            console.log(\`- Workflow Run: \${data.workflowRun.id}\`);
            console.log(\`- SHA: \${data.workflowRun.sha.substring(0, 8)}\`);
            console.log(\`- Failed Jobs: \${data.summary.totalFailedJobs}\`);
            console.log(\`- Total Errors: \${data.summary.totalErrors}\`);
            console.log(\`- Error Types: \${data.summary.errorTypes.join(', ')}\`);
          "
        else
          echo "has_failures=false" >> $GITHUB_OUTPUT
          echo "âœ… No recent failures detected"
        fi
        
    - name: Upload failure analysis
      if: steps.detection.outputs.has_failures == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: failure-analysis
        path: .github/debugging-system/latest-failure-analysis.json
        retention-days: 7

  # Step 2: Generate Fixes
  generate-fixes:
    name: Generate AI-Powered Fixes
    runs-on: ubuntu-latest
    needs: detect-failures
    if: needs.detect-failures.outputs.has_failures == 'true'
    
    outputs:
      fixes_generated: ${{ steps.ai-debug.outputs.fixes_generated }}
      confidence_score: ${{ steps.ai-debug.outputs.confidence_score }}
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        
    - name: Download failure analysis
      uses: actions/download-artifact@v4
      with:
        name: failure-analysis
        path: .github/debugging-system/
        
    - name: Install debugging system dependencies
      run: |
        cd .github/debugging-system
        npm init -y
        npm install @octokit/rest
        
    - name: Run AI debugging analysis
      id: ai-debug
      run: |
        cd .github/debugging-system
        
        echo "ğŸ§  Starting AI-powered fix generation..."
        node ai-debugger.js
        
        if [ -f "proposed-fixes.json" ]; then
          echo "âœ… Fixes generated successfully"
          
          # Extract metrics
          CONFIDENCE=$(node -e "
            const fs = require('fs');
            const data = JSON.parse(fs.readFileSync('proposed-fixes.json', 'utf8'));
            console.log(data.analysis.confidence);
          ")
          
          FIXES_COUNT=$(node -e "
            const fs = require('fs');
            const data = JSON.parse(fs.readFileSync('proposed-fixes.json', 'utf8'));
            console.log(data.fixes.length);
          ")
          
          echo "fixes_generated=true" >> $GITHUB_OUTPUT
          echo "confidence_score=$CONFIDENCE" >> $GITHUB_OUTPUT
          
          echo "ğŸ“Š Fix Generation Summary:"
          echo "- Fixes Generated: $FIXES_COUNT"
          echo "- Confidence Score: $CONFIDENCE"
          
          # Display fix details
          echo "ğŸ”§ Proposed Fixes:"
          node -e "
            const fs = require('fs');
            const data = JSON.parse(fs.readFileSync('proposed-fixes.json', 'utf8'));
            data.fixes.forEach((fix, i) => {
              console.log(\`\${i+1}. File: \${fix.filePath}\`);
              console.log(\`   Description: \${fix.consolidatedFix.description}\`);
              console.log(\`   Confidence: \${fix.confidence}\`);
            });
          "
        else
          echo "fixes_generated=false" >> $GITHUB_OUTPUT
          echo "âŒ No fixes could be generated"
        fi
        
    - name: Upload fix proposals
      if: steps.ai-debug.outputs.fixes_generated == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: proposed-fixes
        path: .github/debugging-system/proposed-fixes.json
        retention-days: 7

  # Step 3: Apply and Test Fixes
  apply-and-test:
    name: Apply Fixes and Test
    runs-on: ubuntu-latest
    needs: [detect-failures, generate-fixes]
    if: needs.generate-fixes.outputs.fixes_generated == 'true' && needs.generate-fixes.outputs.confidence_score > '0.8'
    
    permissions:
      contents: write
      pull-requests: write
      
    outputs:
      fixes_applied: ${{ steps.apply-fixes.outputs.fixes_applied }}
      tests_passed: ${{ steps.test-fixes.outputs.tests_passed }}
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
        
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
        
    - name: Download proposed fixes
      uses: actions/download-artifact@v4
      with:
        name: proposed-fixes
        path: .github/debugging-system/
        
    - name: Apply generated fixes
      id: apply-fixes
      run: |
        cd .github/debugging-system
        
        echo "ğŸ”§ Applying AI-generated fixes..."
        
        # Create fix application script
        cat > apply-fixes.js << 'EOF'
        const fs = require('fs');
        const path = require('path');
        
        async function applyFixes() {
          const fixData = JSON.parse(fs.readFileSync('proposed-fixes.json', 'utf8'));
          let appliedCount = 0;
          
          for (const fileFix of fixData.fixes) {
            const { filePath, consolidatedFix } = fileFix;
            
            try {
              if (consolidatedFix.command) {
                console.log(`ğŸ”„ Running command: ${consolidatedFix.command}`);
                // Commands will be run separately in the workflow
                continue;
              }
              
              if (consolidatedFix.fix && filePath) {
                console.log(`ğŸ“ Applying fix to: ${filePath}`);
                const fullPath = path.resolve('../../', filePath);
                
                // Apply the fix
                if (typeof consolidatedFix.fix === 'string') {
                  await fs.promises.writeFile(fullPath, consolidatedFix.fix);
                  appliedCount++;
                  console.log(`âœ… Applied fix to ${filePath}`);
                }
              }
            } catch (error) {
              console.error(`âŒ Failed to apply fix to ${filePath}:`, error.message);
            }
          }
          
          console.log(`ğŸ“Š Applied ${appliedCount} fixes`);
          return appliedCount;
        }
        
        applyFixes().catch(console.error);
        EOF
        
        # Run fix application
        APPLIED_COUNT=$(node apply-fixes.js)
        
        # Check for command-based fixes
        COMMANDS=$(node -e "
          const fs = require('fs');
          const data = JSON.parse(fs.readFileSync('proposed-fixes.json', 'utf8'));
          const commands = data.fixes
            .map(f => f.consolidatedFix.command)
            .filter(c => c);
          console.log(commands.join('\n'));
        ")
        
        if [ ! -z "$COMMANDS" ]; then
          echo "ğŸ”„ Running fix commands..."
          echo "$COMMANDS" | while read cmd; do
            if [ ! -z "$cmd" ]; then
              echo "Running: $cmd"
              cd ../../ && eval "$cmd"
            fi
          done
        fi
        
        echo "fixes_applied=true" >> $GITHUB_OUTPUT
        
    - name: Install dependencies and run tests
      id: test-fixes
      run: |
        echo "ğŸ§ª Testing applied fixes..."
        
        # Install Python dependencies
        if [ -f "requirements.txt" ]; then
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
        fi
        
        # Install Node.js dependencies
        if [ -f "frontend/package-lock.json" ]; then
          cd frontend
          npm ci
          cd ..
        fi
        
        # Run the same tests that failed
        echo "ğŸ” Running Python linting..."
        if command -v flake8 &> /dev/null; then
          flake8 goreal/ tests/ scripts/ --max-line-length=88 --extend-ignore=E203,W503 || true
        fi
        
        if command -v black &> /dev/null; then
          black --check goreal/ tests/ scripts/ || true
        fi
        
        # Run Python tests
        echo "ğŸ§ª Running Python tests..."
        if command -v pytest &> /dev/null; then
          pytest tests/ --maxfail=5 -x || true
        fi
        
        # Run frontend tests
        if [ -d "frontend" ]; then
          echo "ğŸ§ª Running frontend tests..."
          cd frontend
          npm test -- --watchAll=false --passWithNoTests || true
          cd ..
        fi
        
        # Determine if tests actually passed by checking return codes
        PYTHON_LINT_PASSED=true
        PYTHON_TESTS_PASSED=true  
        FRONTEND_TESTS_PASSED=true
        
        # Check Python linting
        if command -v flake8 &> /dev/null; then
          if ! flake8 goreal/ tests/ scripts/ --max-line-length=88 --extend-ignore=E203,W503 >/dev/null 2>&1; then
            PYTHON_LINT_PASSED=false
            echo "âŒ Python linting still has errors"
          else
            echo "âœ… Python linting passed"
          fi
        fi
        
        if command -v black &> /dev/null; then
          if ! black --check goreal/ tests/ scripts/ >/dev/null 2>&1; then
            PYTHON_LINT_PASSED=false
            echo "âŒ Black formatting still has errors"
          else
            echo "âœ… Black formatting passed"
          fi
        fi
        
        # Check Python tests
        if command -v pytest &> /dev/null; then
          if ! pytest tests/ --maxfail=1 -x >/dev/null 2>&1; then
            PYTHON_TESTS_PASSED=false
            echo "âŒ Python tests still failing"
          else
            echo "âœ… Python tests passed"
          fi
        fi
        
        # Check frontend tests
        if [ -d "frontend" ]; then
          cd frontend
          if ! npm test -- --watchAll=false --passWithNoTests >/dev/null 2>&1; then
            FRONTEND_TESTS_PASSED=false
            echo "âŒ Frontend tests still failing"
          else
            echo "âœ… Frontend tests passed"
          fi
          cd ..
        fi
        
        # Overall test result
        if [ "$PYTHON_LINT_PASSED" = "true" ] && [ "$PYTHON_TESTS_PASSED" = "true" ] && [ "$FRONTEND_TESTS_PASSED" = "true" ]; then
          echo "tests_passed=true" >> $GITHUB_OUTPUT
          echo "ğŸ‰ All tests passed - fix is validated!"
        else
          echo "tests_passed=false" >> $GITHUB_OUTPUT
          echo "âŒ Some tests still failing - fix needs review"
        fi
        
    - name: Auto-commit validated fixes
      if: steps.test-fixes.outputs.tests_passed == 'true' && needs.generate-fixes.outputs.confidence_score > '0.8'
      run: |
        # Configure git for autonomous commits
        git config --local user.email "actions[bot]@github.com"
        git config --local user.name "GoREAL Auto-Fix Bot"
        
        # Check if there are changes to commit
        if ! git diff --quiet; then
          echo "ğŸš€ Auto-committing validated high-confidence fixes..."
          
          # Generate detailed commit message
          cd .github/debugging-system
          
          # Extract fix details for commit message
          WORKFLOW_NAME="${{ github.event.workflow_run.name || 'CI/CD' }}"
          FIX_COUNT=$(node -e "
            const fs = require('fs');
            if (fs.existsSync('proposed-fixes.json')) {
              const data = JSON.parse(fs.readFileSync('proposed-fixes.json', 'utf8'));
              console.log(data.fixes.length);
            } else { console.log('0'); }
          " 2>/dev/null || echo "0")
          
          FIX_TYPES=$(node -e "
            const fs = require('fs');
            if (fs.existsSync('proposed-fixes.json')) {
              const data = JSON.parse(fs.readFileSync('proposed-fixes.json', 'utf8'));
              const types = [...new Set(data.fixes.map(f => f.consolidatedFix.description.split(' ')[0]))];
              console.log(types.slice(0, 3).join(', '));
            } else { console.log('General'); }
          " 2>/dev/null || echo "General")
          
          CONFIDENCE=$(node -e "
            const fs = require('fs');
            if (fs.existsSync('proposed-fixes.json')) {
              const data = JSON.parse(fs.readFileSync('proposed-fixes.json', 'utf8'));
              console.log(Math.round(data.analysis.confidence * 100));
            } else { console.log('85'); }
          " 2>/dev/null || echo "85")
          
          cd ../..
          
          # Create comprehensive commit message
          git add -A
          git commit -m "fix(auto): ${FIX_TYPES} - Resolve ${WORKFLOW_NAME} failures

ğŸ¤– Autonomous Fix Summary:
- Fixed ${FIX_COUNT} issues with ${CONFIDENCE}% confidence
- All tests validated and passing
- Auto-applied by self-healing CI/CD system

Triggered by: ${{ github.event.workflow_run.html_url || github.event_name }}
Run ID: ${{ github.event.workflow_run.id || 'N/A' }}

ğŸ¤– Generated with automated debugging system
Co-Authored-By: GoREAL Auto-Fix Bot <actions[bot]@github.com>"

          # Push the fix
          echo "ğŸ“¤ Pushing autonomous fix to main branch..."
          git push origin main
          
          echo "âœ… Autonomous fix committed successfully!"
          echo "ğŸ”„ This will trigger the original workflow to re-run and should now pass."
          
        else
          echo "â„¹ï¸ No file changes detected - fix may have been command-based only"
        fi

  # Step 4: Create Issue if Fixes Fail
  create-issue:
    name: Create Issue for Manual Review
    runs-on: ubuntu-latest
    needs: [detect-failures, generate-fixes, apply-and-test]
    if: always() && (needs.generate-fixes.outputs.fixes_generated != 'true' || needs.apply-and-test.result == 'failure' || needs.generate-fixes.outputs.confidence_score <= '0.8' || needs.apply-and-test.outputs.tests_passed != 'true')
    
    permissions:
      issues: write
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Download artifacts
      uses: actions/download-artifact@v4
      with:
        pattern: "*"
        merge-multiple: true
        
    - name: Create issue for manual review
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          let analysisData = null;
          let fixData = null;
          
          try {
            analysisData = JSON.parse(fs.readFileSync('latest-failure-analysis.json', 'utf8'));
          } catch (e) {
            console.log('No analysis data found');
          }
          
          try {
            fixData = JSON.parse(fs.readFileSync('proposed-fixes.json', 'utf8'));
          } catch (e) {
            console.log('No fix data found');
          }
          
          let issueBody = `# ğŸ¤– Automated Debugging Report
          
          The automated debugging system has detected CI/CD failures that require manual review.
          
          ## ğŸ“Š Failure Summary
          `;
          
          if (analysisData) {
            issueBody += `
          - **Workflow Run**: ${analysisData.workflowRun.id}
          - **Commit SHA**: ${analysisData.workflowRun.sha}
          - **Branch**: ${analysisData.workflowRun.branch}
          - **Failed Jobs**: ${analysisData.summary.totalFailedJobs}
          - **Total Errors**: ${analysisData.summary.totalErrors}
          - **Error Types**: ${analysisData.summary.errorTypes.join(', ')}
          
          ### Failed Jobs:
          `;
          
            analysisData.failedJobs.forEach(job => {
              issueBody += `
          #### ${job.jobName}
          - **Job ID**: ${job.jobId}
          - **Errors Found**: ${job.analysis.errors.length}
          - **Error Summary**: ${job.analysis.errors.slice(0, 3).map(e => e.message.substring(0, 100)).join(', ')}
          `;
            });
          }
          
          if (fixData) {
            issueBody += `
          ## ğŸ”§ Fix Analysis
          - **Fixes Generated**: ${fixData.fixes.length}
          - **Overall Confidence**: ${fixData.analysis.confidence}
          
          ### Proposed Fixes:
          `;
          
            fixData.fixes.forEach((fix, i) => {
              issueBody += `
          ${i + 1}. **File**: \`${fix.filePath}\`
             - **Description**: ${fix.consolidatedFix.description}
             - **Confidence**: ${fix.confidence}
             ${fix.consolidatedFix.requiresHumanReview ? '- **âš ï¸ Requires Human Review**' : ''}
          `;
            });
          }
          
          issueBody += `
          ## ğŸ› ï¸ Next Steps
          1. Review the failure analysis above
          2. Check the proposed fixes for accuracy
          3. Apply fixes manually if needed
          4. Consider improving the automated debugging rules
          
          **Auto-generated by**: Automated Debugging System
          **Workflow**: ${context.workflow}
          **Run ID**: ${context.runId}
          `;
          
          await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `ğŸ¤– CI/CD Failure Requires Manual Review - ${new Date().toISOString().split('T')[0]}`,
            body: issueBody,
            labels: ['bug', 'automated-debugging', 'ci-cd-failure']
          });

  # Step 5: Notification and Reporting
  notify-results:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [detect-failures, generate-fixes, apply-and-test, create-issue]
    if: always()
    
    steps:
    - name: Report results
      run: |
        echo "ğŸ¯ Automated Debugging Summary"
        echo "=============================="
        
        if [ "${{ needs.detect-failures.outputs.has_failures }}" == "true" ]; then
          echo "âŒ Failures detected: YES"
          
          if [ "${{ needs.generate-fixes.outputs.fixes_generated }}" == "true" ]; then
            echo "ğŸ”§ Fixes generated: YES"
            echo "ğŸ¯ Confidence score: ${{ needs.generate-fixes.outputs.confidence_score }}"
            
            if [ "${{ needs.apply-and-test.outputs.fixes_applied }}" == "true" ]; then
              echo "âœ… Fixes applied: YES"
              
              if [ "${{ needs.apply-and-test.outputs.tests_passed }}" == "true" ]; then
                echo "ğŸ§ª Tests passed: YES"
                echo "ğŸ‰ AUTOMATED DEBUGGING SUCCESS!"
              else
                echo "ğŸ§ª Tests passed: NO"
                echo "ğŸ“ Issue created for manual review"
              fi
            else
              echo "âœ… Fixes applied: NO"
              echo "ğŸ“ Issue created for manual review"
            fi
          else
            echo "ğŸ”§ Fixes generated: NO"
            echo "ğŸ“ Issue created for manual review"
          fi
        else
          echo "âœ… No failures detected"
          echo "ğŸ‰ All systems operational!"
        fi